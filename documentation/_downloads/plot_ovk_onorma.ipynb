{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n# Online Learning with Operator-Valued kernels\n\n\nAn example to illustrate online learning with operator-valued\nkernels.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import operalib as ovk\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport time\n\nnp.random.seed(0)\n\nn = 5000\nd = 20\np = 4\nX = np.random.rand(n, d)\n\n\ndef phi(X):\n    \"\"\"Generate data according to Evgeniou, C. A. Micchelli, and M. Pontil.\n\n    'Learning multiple tasks with kernel methods.' 2005.\n    \"\"\"\n    return np.hstack((X[:, 0:1] ** 2,\n                      X[:, 3:4] ** 2,\n                      X[:, 0:1] * X[:, 1:2],\n                      X[:, 2:3] * X[:, 4:5],\n                      X[:, 1:2],\n                      X[:, 3:4],\n                      np.ones((n, 1))))\n\n\nprint('Generating Data')\ny = np.dot(phi(X), np.random.multivariate_normal(np.zeros(7),\n                                                 np.diag([0.5, 0.25, 0.1, 0.05,\n                                                          0.15, 0.1, 0.15]),\n                                                 p).T)\n\n# Link components to a common mean.\ny = .5 * y + 0.5 * np.mean(y, axis=1).reshape(-1, 1)\n\nest = ovk.ONORMA('DGauss', A=1. * np.eye(p) + .0 * np.ones((p, p)), gamma=.1,\n                 learning_rate=ovk.InvScaling(1.0, 0.5), lbda=0.00001)\nprint('Fitting Independant...')\nstart = time.time()\nerr_i = np.empty(n)\nerr_i[0] = np.linalg.norm(y[0, :]) ** 2\nest.partial_fit(X[0, :].reshape(1, -1), y[0, :])\nfor t in range(1, n):\n    err_i[t] = np.linalg.norm(est.predict(X[t, :].reshape(1, -1)) -\n                              y[t, :]) ** 2\n    est.partial_fit(X[t, :], y[t, :])\nerr_ci = np.cumsum(err_i) / (np.arange(n) + 1)\nprint('Independant training time:', time.time() - start)\nprint('Independant MSE:', err_ci[-1])\nplt.semilogy(np.linspace(0, 100, err_ci.size), err_ci, label='Independant')\n\nest = ovk.ONORMA('DGauss', A=.9 * np.eye(p) + 0.1 * np.ones((p, p)), gamma=.1,\n                 learning_rate=ovk.InvScaling(1.0, 0.5), lbda=0.00001)\nprint('Fitting Joint...')\nstart = time.time()\nerr_j = np.empty(n)\nerr_j[0] = np.linalg.norm(y[0, :]) ** 2\nest.partial_fit(X[0, :].reshape(1, -1), y[0, :])\nfor t in range(1, n):\n    err_j[t] = np.linalg.norm(est.predict(X[t, :].reshape(1, -1)) -\n                              y[t, :]) ** 2\n    est.partial_fit(X[t, :], y[t, :])\nerr_cj = np.cumsum(err_j) / (np.arange(n) + 1)\nprint('Joint training time:', time.time() - start)\nprint('Joint MSE:', err_cj[-1])\nplt.semilogy(np.linspace(0, 100, err_cj.size), err_cj, label='Joint')\n\nplt.ylim(0.017, 1.2e-1)\nplt.title('Online learning with ONORMA')\nplt.xlabel('Size of the Training set (%)')\nplt.ylabel('MSE')\nplt.legend()\nplt.show()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.6", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}