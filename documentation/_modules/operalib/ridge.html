

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>operalib.ridge &mdash; Operalib 0.1.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../../genindex.html"/>
        <link rel="search" title="Search" href="../../search.html"/>
    <link rel="top" title="Operalib 0.1.0 documentation" href="../../index.html"/>
        <link rel="up" title="Module code" href="../index.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> Operalib
          

          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../auto_examples/index.html">General examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference_papers/index.html">Reference papers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contact.html">Contact</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Operalib</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>operalib.ridge</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for operalib.ridge</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">:mod:`operalib.ridge` implements Operator-Valued Kernel ridge</span>
<span class="sd">regression.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Author: Romain Brault &lt;romain.brault@telecom-paristech.fr&gt; with help from</span>
<span class="c1">#         the scikit-learn community.</span>
<span class="c1">#         Maxime Sangnier &lt;maxime.sangnier@gmail.com&gt;</span>
<span class="c1"># License: MIT</span>

<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="k">import</span> <span class="n">minimize</span>
<span class="kn">from</span> <span class="nn">scipy.sparse.linalg</span> <span class="k">import</span> <span class="n">LinearOperator</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="k">import</span> <span class="p">(</span><span class="n">reshape</span><span class="p">,</span> <span class="n">eye</span><span class="p">,</span> <span class="n">zeros</span><span class="p">,</span> <span class="n">empty</span><span class="p">,</span> <span class="n">dot</span><span class="p">,</span> <span class="nb">all</span><span class="p">,</span> <span class="n">isnan</span><span class="p">,</span> <span class="n">diag</span><span class="p">,</span> <span class="n">number</span><span class="p">,</span>
                   <span class="n">issubdtype</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="k">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">RegressorMixin</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="k">import</span> <span class="n">check_array</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="k">import</span> <span class="n">check_is_fitted</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="k">import</span> <span class="n">rbf_kernel</span>

<span class="kn">from</span> <span class="nn">.metrics</span> <span class="k">import</span> <span class="n">first_periodic_kernel</span>
<span class="kn">from</span> <span class="nn">.kernels</span> <span class="k">import</span> <span class="n">DecomposableKernel</span><span class="p">,</span> <span class="n">RBFCurlFreeKernel</span>
<span class="kn">from</span> <span class="nn">.risk</span> <span class="k">import</span> <span class="n">OVKRidgeRisk</span>
<span class="kn">from</span> <span class="nn">.signal</span> <span class="k">import</span> <span class="n">get_period</span>

<span class="c1"># When adding a new kernel, update this table and the _get_kernel_map method</span>
<span class="n">PAIRWISE_KERNEL_FUNCTIONS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;DGauss&#39;</span><span class="p">:</span> <span class="n">DecomposableKernel</span><span class="p">,</span>
    <span class="s1">&#39;DPeriodic&#39;</span><span class="p">:</span> <span class="n">DecomposableKernel</span><span class="p">,</span>
    <span class="s1">&#39;CurlF&#39;</span><span class="p">:</span> <span class="n">RBFCurlFreeKernel</span><span class="p">}</span>


<span class="k">def</span> <span class="nf">_graph_Laplacian</span><span class="p">(</span><span class="n">similarities</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">diag</span><span class="p">(</span><span class="n">similarities</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="o">-</span> <span class="n">similarities</span>


<span class="k">class</span> <span class="nc">_SemisupLinop</span><span class="p">:</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lbda2</span><span class="p">,</span> <span class="n">is_sup</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lbda2</span> <span class="o">=</span> <span class="n">lbda2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_sup</span> <span class="o">=</span> <span class="n">is_sup</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">L</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ns</span> <span class="o">=</span> <span class="n">is_sup</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">L</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ls</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_dot_U</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vec</span><span class="p">):</span>
        <span class="n">mat</span> <span class="o">=</span> <span class="n">vec</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">ns</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ls</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">))</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">empty</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">ns</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ls</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">))</span>
        <span class="n">res</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">is_sup</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">mat</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">is_sup</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">res</span><span class="p">[</span><span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">is_sup</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lbda2</span> <span class="o">*</span> <span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="n">mat</span><span class="p">[</span><span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">is_sup</span><span class="p">,</span> <span class="p">:])</span>

        <span class="k">return</span> <span class="n">res</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_dot_JT</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vec</span><span class="p">):</span>
        <span class="n">mat</span> <span class="o">=</span> <span class="n">vec</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">ns</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ls</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">))</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">empty</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">ns</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ls</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">))</span>
        <span class="n">res</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">is_sup</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">mat</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">is_sup</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">res</span><span class="p">[</span><span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">is_sup</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">return</span> <span class="n">res</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">gen</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">shape_U</span> <span class="o">=</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">ns</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ls</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ns</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ls</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
        <span class="n">shape_JT</span> <span class="o">=</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">ns</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ls</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ns</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ls</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>

        <span class="c1"># return U, JT</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">LinearOperator</span><span class="p">(</span><span class="n">shape_U</span><span class="p">,</span>
                               <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                               <span class="n">matvec</span><span class="o">=</span><span class="k">lambda</span> <span class="n">b</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dot_U</span><span class="p">(</span><span class="n">b</span><span class="p">),</span>
                               <span class="n">rmatvec</span><span class="o">=</span><span class="k">lambda</span> <span class="n">b</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dot_U</span><span class="p">(</span><span class="n">b</span><span class="p">)),</span>
                <span class="n">LinearOperator</span><span class="p">(</span><span class="n">shape_JT</span><span class="p">,</span>
                               <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                               <span class="n">matvec</span><span class="o">=</span><span class="k">lambda</span> <span class="n">b</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dot_JT</span><span class="p">(</span><span class="n">b</span><span class="p">),</span>
                               <span class="n">rmatvec</span><span class="o">=</span><span class="k">lambda</span> <span class="n">b</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dot_JT</span><span class="p">(</span><span class="n">b</span><span class="p">)))</span>


<div class="viewcode-block" id="OVKRidge"><a class="viewcode-back" href="../../modules/ridge.html#operalib.ridge.OVKRidge">[docs]</a><span class="k">class</span> <span class="nc">OVKRidge</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">RegressorMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Operator-Valued kernel ridge regression.</span>

<span class="sd">    Operator-Valued kernel ridge regression (OVKRR) combines ridge regression</span>
<span class="sd">    (linear least squares with l2-norm regularization) with the (OV)kernel</span>
<span class="sd">    trick. It learns a linear function in the space induced by the</span>
<span class="sd">    respective kernel and the data. For non-linear kernels, this corresponds to</span>
<span class="sd">    a non-linear function in the original space.</span>

<span class="sd">    The form of the model learned by OVKRR is identical to support vector</span>
<span class="sd">    regression (SVR). However, different loss functions are used: OVKRR uses</span>
<span class="sd">    squared error loss while support vector regression uses epsilon-insensitive</span>
<span class="sd">    loss, both combined with l2 regularization. In contrast to SVR, fitting a</span>
<span class="sd">    OVKRR model can be done in closed-form and is typically faster for</span>
<span class="sd">    medium-sized datasets. On the other  hand, the learned model is non-sparse</span>
<span class="sd">    and thus slower than SVR, which learns a sparse model for epsilon &gt; 0, at</span>
<span class="sd">    prediction-time.</span>

<span class="sd">    Optimization problem solved for learning:</span>
<span class="sd">    .. math::</span>
<span class="sd">        \min_{h \in \mathcal H}~ \frac{\lambda}{2} \|h\|_{\mathcal H}^2 +</span>
<span class="sd">        \frac{1}{np} \sum_{i=1}^n \|y_j - h(x_i)\|_{\mathcal Y}^2 +</span>
<span class="sd">        \frac{\lambda_m}{2} \sum_{i=1}^n W_{ij}</span>
<span class="sd">        \|h(x_i) - h(x_j)\|_{\mathcal Y}^2</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    dual_coef_ : array, shape = [n_samples x n_targest]</span>
<span class="sd">        Weight vector(s) in kernel space</span>

<span class="sd">    linop_ : callable</span>
<span class="sd">        Callable which associate to the training points X the Gram matrix (the</span>
<span class="sd">        Gram matrix being a LinearOperator)</span>

<span class="sd">    A_ : array, shape = [n_targets, n_targets]</span>
<span class="sd">        Set when Linear operator used by the decomposable kernel is default or</span>
<span class="sd">        None.</span>

<span class="sd">    L_ : array, shape = [n_samples_miss, n_samples_miss]</span>
<span class="sd">        Graph Laplacian of data with missing targets (semi-supervised</span>
<span class="sd">        learning).</span>

<span class="sd">    period_ : float</span>
<span class="sd">        Set when period used by the First periodic kernel is &#39;autocorr&#39;.</span>

<span class="sd">    solver_res_ : any</span>
<span class="sd">        Raw results returned by the solver.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    * Micchelli, Charles A., and Massimiliano Pontil.</span>
<span class="sd">      &quot;On learning vector-valued functions.&quot; Neural computation</span>
<span class="sd">      17.1 (2005): 177-204.</span>

<span class="sd">    * Alvarez, Mauricio A., Lorenzo Rosasco, and Neil D. Lawrence.</span>
<span class="sd">      &quot;Kernels for vector-valued functions: A review.&quot; arXiv preprint</span>
<span class="sd">      arXiv:1106.6251 (2011). APA</span>

<span class="sd">    * Brouard Celine, d&#39;Alche-Buc Florence and Szafranski Marie.</span>
<span class="sd">      &quot;Input Output Kernel Regression,&quot; Hal preprint</span>
<span class="sd">      hal-01216708 (2015).</span>


<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    sklearn.OVKRidge</span>
<span class="sd">        Linear ridge regression.</span>
<span class="sd">    sklearn.KernelOVKRidge</span>
<span class="sd">        Kernel ridge regression.</span>
<span class="sd">    sklearn.SVR</span>
<span class="sd">        Support Vector Regression implemented using libsvm.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import operalib as ovk</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; n_samples, n_features, n_targets = 10, 5, 5</span>
<span class="sd">    &gt;&gt;&gt; rng = np.random.RandomState(0)</span>
<span class="sd">    &gt;&gt;&gt; y = rng.randn(n_samples, n_targets)</span>
<span class="sd">    &gt;&gt;&gt; X = rng.randn(n_samples, n_features)</span>
<span class="sd">    &gt;&gt;&gt; clf = ovk.OVKRidge(&#39;DGauss&#39;, lbda=1.0)</span>
<span class="sd">    &gt;&gt;&gt; clf.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS</span>
<span class="sd">    OVKRidge(...)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">ovkernel</span><span class="o">=</span><span class="s1">&#39;DGauss&#39;</span><span class="p">,</span> <span class="n">lbda</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">lbda_m</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>
                 <span class="n">A</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">gamma_m</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
                 <span class="n">period</span><span class="o">=</span><span class="s1">&#39;autocorr&#39;</span><span class="p">,</span> <span class="n">autocorr_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span> <span class="n">solver_params</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize OVK ridge regression model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        ovkernel : {string, callable}, default=&#39;DGauss&#39;</span>
<span class="sd">            Kernel mapping used internally. A callable should accept two</span>
<span class="sd">            arguments, and should return a LinearOperator.</span>

<span class="sd">        lbda : {float}, default=1e-5</span>
<span class="sd">            Small positive values of lbda improve the conditioning of the</span>
<span class="sd">            problem and reduce the variance of the estimates.  Lbda corresponds</span>
<span class="sd">            to ``(2*C)^-1`` in other linear models such as LogisticRegression</span>
<span class="sd">            or LinearSVC.</span>

<span class="sd">        lbda_m : {float}, default=0.</span>
<span class="sd">            Regularization parameter for quadratic penalty on data with missing</span>
<span class="sd">            targets.</span>

<span class="sd">        A : {LinearOperator, array-like, sparse matrix}, default=None</span>
<span class="sd">            Linear operator used by the decomposable kernel. If default is</span>
<span class="sd">            None, wich is set to identity matrix of size y.shape[1] when</span>
<span class="sd">            fitting.</span>

<span class="sd">        gamma : {float}, default=None.</span>
<span class="sd">            Gamma parameter for the Decomposable Gaussian kernel.</span>
<span class="sd">            Ignored by other kernels.</span>

<span class="sd">        gamma_m : {float}, default=None.</span>
<span class="sd">            Gamma parameter for the graph Laplacian inducing penalty on data</span>
<span class="sd">            with missing targets.</span>

<span class="sd">        theta : {float}, default=.7</span>
<span class="sd">            Theta parameter for the Decomposable First Periodic kernel.</span>
<span class="sd">            Ignored by other kernels.</span>

<span class="sd">        period : {float}, default=default_period</span>
<span class="sd">            Period parameter for the First periodic kernel. If optional modules</span>
<span class="sd">            have been imported then default_period is 2 * pi. Otherwise it uses</span>
<span class="sd">            autocorrelation methods to determine the period.</span>

<span class="sd">        solver : {callable}, default=scipy.optimize.fmin_l_bfgs_b</span>
<span class="sd">            Solver able to find the minimum of the ridge problem.</span>
<span class="sd">            scipy.optimize.fmin_l_bfgs_b(*solver_params)[0] must return the</span>
<span class="sd">            optimal solution.</span>

<span class="sd">        autocorr_params : {mapping of string to any}</span>
<span class="sd">            Additional parameters (keyword arguments) for the period detection</span>
<span class="sd">            for periodic kernels. If None, parameter choice is left to the</span>
<span class="sd">            period detection method.</span>

<span class="sd">        solver_params : {mapping of string to any}, optional</span>
<span class="sd">            Additional parameters (keyword arguments) for solver function</span>
<span class="sd">            passed as callable object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ovkernel</span> <span class="o">=</span> <span class="n">ovkernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lbda</span> <span class="o">=</span> <span class="n">lbda</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lbda_m</span> <span class="o">=</span> <span class="n">lbda_m</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">=</span> <span class="n">A</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma_m</span> <span class="o">=</span> <span class="n">gamma_m</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">=</span> <span class="n">period</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">autocorr_params</span> <span class="o">=</span> <span class="n">autocorr_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">=</span> <span class="n">solver</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">solver_params</span> <span class="o">=</span> <span class="n">solver_params</span>

    <span class="k">def</span> <span class="nf">_validate_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># check on self.ovkernel is performed in method __get_kernel</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lbda</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;lbda must be positive&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lbda_m</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;lbda_m must be positive&#39;</span><span class="p">)</span>
        <span class="c1"># if self.A &lt; 0: # Check whether A is S PD would be really expensive</span>
        <span class="c1">#     raise ValueError(&#39;A must be a symmetric positive operator&#39;)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;sigma must be positive or default (None)&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;theta must be positive&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">period</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;period must be positive&#39;</span><span class="p">)</span>
        <span class="c1"># TODO, add supported solver check</span>

    <span class="k">def</span> <span class="nf">_default_decomposable_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="c1"># TODO: check NaN values (semi-sup learning)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span>
        <span class="k">elif</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">eye</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">eye</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_default_period</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="ow">is</span> <span class="s1">&#39;autocorr&#39;</span><span class="p">:</span>
            <span class="n">autocorr_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">autocorr_params</span> <span class="ow">or</span> <span class="p">{}</span>
            <span class="k">return</span> <span class="n">get_period</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">autocorr_params</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">period</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">period</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;period must be a positive number or a valid &#39;</span>
                             <span class="s1">&#39;string&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_kernel_map</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="c1"># When adding a new kernel, update this table and the _get_kernel_map</span>
        <span class="c1"># method</span>
        <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ovkernel</span><span class="p">):</span>
            <span class="n">ovkernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ovkernel</span>
        <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ovkernel</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">str</span><span class="p">:</span>
            <span class="c1"># 1) check string and assign the right parameters</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ovkernel</span> <span class="o">==</span> <span class="s1">&#39;DGauss&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">A_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_decomposable_op</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
                <span class="n">kernel_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;A&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">A_</span><span class="p">,</span> <span class="s1">&#39;scalar_kernel&#39;</span><span class="p">:</span> <span class="n">rbf_kernel</span><span class="p">,</span>
                                 <span class="s1">&#39;scalar_kernel_params&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">}}</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">ovkernel</span> <span class="o">==</span> <span class="s1">&#39;DPeriodic&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">A_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_decomposable_op</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">period_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_period</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                <span class="n">kernel_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;A&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">A_</span><span class="p">,</span>
                                 <span class="s1">&#39;scalar_kernel&#39;</span><span class="p">:</span> <span class="n">first_periodic_kernel</span><span class="p">,</span>
                                 <span class="s1">&#39;scalar_kernel_params&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span>
                                                          <span class="s1">&#39;period&#39;</span><span class="p">:</span>
                                                          <span class="bp">self</span><span class="o">.</span><span class="n">period_</span><span class="p">},</span> <span class="p">}</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">ovkernel</span> <span class="o">==</span> <span class="s1">&#39;CurlF&#39;</span><span class="p">:</span>
                <span class="n">kernel_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;unsupported kernel&#39;</span><span class="p">)</span>
            <span class="c1"># 2) Uses lookup table to select the right kernel from string</span>
            <span class="n">ovkernel</span> <span class="o">=</span> <span class="n">PAIRWISE_KERNEL_FUNCTIONS</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">ovkernel</span><span class="p">](</span>
                <span class="o">**</span><span class="n">kernel_params</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;unsupported kernel&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ovkernel</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_decision_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linop_</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dual_coefs_</span>

        <span class="k">return</span> <span class="n">reshape</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">linop_</span><span class="o">.</span><span class="n">p</span><span class="p">))</span> \
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">linop_</span><span class="o">.</span><span class="n">p</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">pred</span>

<div class="viewcode-block" id="OVKRidge.fit"><a class="viewcode-back" href="../../modules/ridge.html#operalib.ridge.OVKRidge.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fit OVK ridge regression model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix}, shape = [n_samples, n_features]</span>
<span class="sd">            Training data.</span>

<span class="sd">        y : {array-like}, shape = [n_samples] or [n_samples, n_targets]</span>
<span class="sd">            Target values. numpy.NaN for missing targets (semi-supervised</span>
<span class="sd">            learning).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : returns an instance of self.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_params</span><span class="p">()</span>

        <span class="n">solver_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver_params</span> <span class="ow">or</span> <span class="p">{}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">linop_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_kernel_map</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">Gram</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linop_</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">risk</span> <span class="o">=</span> <span class="n">OVKRidgeRisk</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lbda</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">issubdtype</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">number</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unknown label type: </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">y</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">is_sup</span> <span class="o">=</span> <span class="o">~</span><span class="nb">all</span><span class="p">(</span><span class="n">isnan</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">is_sup</span> <span class="o">=</span> <span class="o">~</span><span class="n">isnan</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="o">~</span><span class="n">is_sup</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">L_</span> <span class="o">=</span> <span class="n">_graph_Laplacian</span><span class="p">(</span><span class="n">rbf_kernel</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="o">~</span><span class="n">is_sup</span><span class="p">,</span> <span class="p">:],</span>
                                                  <span class="n">gamma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_m</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">L_</span> <span class="o">=</span> <span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

        <span class="n">p</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">1</span>
        <span class="n">weight</span><span class="p">,</span> <span class="n">zeronan</span> <span class="o">=</span> <span class="n">_SemisupLinop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lbda_m</span><span class="p">,</span> <span class="n">is_sup</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">L_</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">gen</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">solver_res_</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">risk</span><span class="o">.</span><span class="n">functional_grad_val</span><span class="p">,</span>
                                    <span class="n">zeros</span><span class="p">(</span><span class="n">Gram</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                                    <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">Gram</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">zeronan</span><span class="p">),</span>
                                    <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">,</span>
                                    <span class="n">jac</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                    <span class="n">options</span><span class="o">=</span><span class="n">solver_params</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dual_coefs_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver_res_</span><span class="o">.</span><span class="n">x</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="OVKRidge.predict"><a class="viewcode-back" href="../../modules/ridge.html#operalib.ridge.OVKRidge.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict using the OVK ridge model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix}, shape = [n_samples, n_features]</span>
<span class="sd">            Samples.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        C : {array}, shape = [n_samples] or [n_samples, n_targets]</span>
<span class="sd">            Returns predicted values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;dual_coefs_&#39;</span><span class="p">,</span> <span class="s1">&#39;linop_&#39;</span><span class="p">],</span> <span class="n">all_or_any</span><span class="o">=</span><span class="nb">all</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></div></div>
</pre></div>

           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Romain Brault.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'0.1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>